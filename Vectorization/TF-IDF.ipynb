{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF(Term Frequency-Inverse Document Frequency)\n",
    "This notebook explains the TF-IDF method in Natural Language Processing (NLP), \n",
    "\n",
    "covering both mathematical foundations and practical implementation in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. History and Background\n",
    "\n",
    "TF-IDF is one of the most popular weighting schemes in information retrieval and text mining.\n",
    "\n",
    "- **1950s-1960s**: The concept originates from information retrieval research\n",
    "- **1972**: First formal mention by Karen Spärck Jones in her paper \"A Statistical Interpretation of Term Specificity and Its Application in Retrieval\"\n",
    "- **1980s-1990s**: Became standard in search engines and document classification\n",
    "- **Present**: Still widely used as a baseline in text processing and NLP tasks\n",
    "\n",
    "TF-IDF reflects how important a word is to a document in a collection or corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mathematical Foundations\n",
    "\n",
    "TF-IDF is composed of two components:\n",
    "\n",
    "### Term Frequency (TF)\n",
    "Measures how frequently a term occurs in a document:\n",
    "\n",
    "$$ tf(t,d) = \\frac{\\text{Number of times term } t \\text{ appears in document } d}{\\text{Total number of terms in document } d} $$\n",
    "\n",
    "### Inverse Document Frequency (IDF)\n",
    "Measures how important a term is across the entire corpus:\n",
    "\n",
    "$$ idf(t,D) = \\log\\left(\\frac{\\text{Total number of documents in corpus } D}{\\text{Number of documents containing term } t}\\right) $$\n",
    "\n",
    "### TF-IDF\n",
    "The product of TF and IDF:\n",
    "\n",
    "$$ tfidf(t,d,D) = tf(t,d) \\times idf(t,D) $$\n",
    "\n",
    "Variations exist for both TF and IDF calculations (logarithmic, augmented, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Python Implementation\n",
    "\n",
    "Let's implement TF-IDF from scratch and compare with scikit-learn's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"the sky is blue\",\n",
    "    \"the sun is bright\",\n",
    "    \"the sun in the sky is bright\",\n",
    "    \"we can see the shining sun, the bright sun\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf(text):\n",
    "    \"\"\"Compute Term Frequency for a single document\"\"\"\n",
    "    tf_dict = {}\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    \n",
    "    for word in words:\n",
    "        tf_dict[word] = tf_dict.get(word, 0) + 1/word_count\n",
    "    \n",
    "    return tf_dict\n",
    "\n",
    "def compute_idf(docs):\n",
    "    \"\"\"Compute Inverse Document Frequency for all documents\"\"\"\n",
    "    idf_dict = defaultdict(lambda: 0)\n",
    "    total_docs = len(docs)\n",
    "    \n",
    "    for doc in docs:\n",
    "        words = set(doc.split())\n",
    "        for word in words:\n",
    "            idf_dict[word] += 1\n",
    "    \n",
    "    for word in idf_dict:\n",
    "        idf_dict[word] = math.log(total_docs / idf_dict[word])\n",
    "    \n",
    "    return idf_dict\n",
    "\n",
    "def compute_tfidf(docs):\n",
    "    \"\"\"Compute TF-IDF for all documents\"\"\"\n",
    "    tfidf = []\n",
    "    idf = compute_idf(docs)\n",
    "    \n",
    "    for doc in docs:\n",
    "        tf = compute_tf(doc)\n",
    "        doc_tfidf = {}\n",
    "        \n",
    "        for word in tf:\n",
    "            doc_tfidf[word] = tf[word] * idf[word]\n",
    "        \n",
    "        tfidf.append(doc_tfidf)\n",
    "    \n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TF-IDF using our implementation\n",
    "tfidf_results = compute_tfidf(documents)\n",
    "\n",
    "# Display results\n",
    "for i, doc in enumerate(tfidf_results):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    for word, score in doc.items():\n",
    "        print(f\"  {word}: {score:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using scikit-learn's TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "tfidf_sklearn = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "df_tfidf = pd.DataFrame(\n",
    "    tfidf_sklearn.toarray(),\n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "print(\"TF-IDF Matrix from scikit-learn:\")\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Applications and References\n",
    "\n",
    "### Applications:\n",
    "- Search engine ranking\n",
    "- Document classification\n",
    "- Keyword extraction\n",
    "- Text summarization\n",
    "- Information retrieval systems\n",
    "\n",
    "### References:\n",
    "1. Spärck Jones, K. (1972). \"A statistical interpretation of term specificity and its application in retrieval\". Journal of Documentation.\n",
    "2. Manning, C. D., Raghavan, P., & Schütze, H. (2008). \"Introduction to Information Retrieval\". Cambridge University Press.\n",
    "3. Jurafsky, D., & Martin, J. H. (2020). \"Speech and Language Processing\". Pearson.\n",
    "4. Scikit-learn documentation: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "### Limitations:\n",
    "- Doesn't capture semantic meaning\n",
    "- Treats words as independent features\n",
    "- Can be computationally expensive for large vocabularies\n",
    "\n",
    "Modern alternatives include word embeddings (Word2Vec, GloVe) and transformer-based models (BERT)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
