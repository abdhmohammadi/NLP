{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "23b089cb",
      "metadata": {
        "id": "23b089cb"
      },
      "source": [
        "# Text Vectorization Example\n",
        "\n",
        "This notebook demonstrates how to build a simple text vectorizer from scratch. It covers:\n",
        "- Creating a vocabulary\n",
        "- Encoding text to numerical tokens\n",
        "- Decoding tokens back to text\n",
        "- Handling unknown (out-of-vocabulary) words\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d795842",
      "metadata": {
        "id": "4d795842"
      },
      "source": [
        "## 1. Importing the Vectorizer\n",
        "\n",
        "We start by importing our custom `TextVectorization` module and initializing the `Vectorizer` class. Then, we prepare a small dataset to work with.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4nHz_ZEnKizP",
      "metadata": {
        "id": "4nHz_ZEnKizP"
      },
      "source": [
        "First must be initalize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "vFmlnZH0KAZw",
      "metadata": {
        "id": "vFmlnZH0KAZw"
      },
      "outputs": [],
      "source": [
        "# Sample dataset of short sentences\n",
        "dataset = [\n",
        "    \"I write, erase, rewrite\",\n",
        "    \"Erase again, and then\",\n",
        "    \"A poppy blooms.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "93211287",
      "metadata": {
        "id": "93211287"
      },
      "outputs": [],
      "source": [
        "# Import the vectorizer module\n",
        "import TextVectorization as tv\n",
        "\n",
        "# Initialize the vectorizer\n",
        "vectorizer = tv.Vectorizer()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9929069b",
      "metadata": {
        "id": "9929069b"
      },
      "source": [
        "## 2. Creating Vocabulary\n",
        "\n",
        "Encoding/Decoding a Sentence\n",
        "\n",
        "We build the vocabulary from the dataset, encode a sentence into tokens (numbers), and then decode it back into text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "681a2c03",
      "metadata": {
        "id": "681a2c03",
        "outputId": "84526e39-fa73-41bd-96ab-475549455b61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded: [2, 3, 5, 7, 1, 5, 6]\n",
            "Decoded: i write rewrite and [UNK] rewrite again\n"
          ]
        }
      ],
      "source": [
        "# Build vocabulary from the dataset\n",
        "vectorizer.make_vocabulary(dataset)\n",
        "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
        "# Encode the sentence to tokens\n",
        "encoded = vectorizer.encode(test_sentence)\n",
        "print(f'Encoded: {encoded}')  # Example: [2, 3, 4, 5]\n",
        "\n",
        "# Decode the tokens back to words\n",
        "print(f'Decoded: {vectorizer.decode(encoded)}')  # Example: i write erase rewrite\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "463fed94",
      "metadata": {
        "id": "463fed94"
      },
      "source": [
        "## 3. Handling Unknown Words\n",
        "\n",
        "Now we try encoding a sentence with words not in the original vocabulary. The unknown words are replaced by a special `[UNK]` token.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "51ea9904",
      "metadata": {
        "id": "51ea9904",
        "outputId": "0a48e694-ec53-496a-a347-f4b18de2dfb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded: [2, 1, 9, 1, 1]\n",
            "Decoded: i [UNK] a [UNK] [UNK]\n"
          ]
        }
      ],
      "source": [
        "sample_text = \"I am a book lover\"\n",
        "encoded = vectorizer.encode(sample_text)\n",
        "print(f'Encoded: {encoded}') \n",
        "print(f'Decoded: {vectorizer.decode(encoded)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af9ccd29",
      "metadata": {},
      "source": [
        "The result shows three `[KNK]` cases associated with three locations marked with `index = 1`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k4R3QM-nHvP7",
      "metadata": {
        "id": "k4R3QM-nHvP7"
      },
      "source": [
        "## 4. TextVectorization by Keras\n",
        "\n",
        "To build vocabulary in Kras, just call `tv.adapt(dataset)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "pWxsSyP1H3HW",
      "metadata": {
        "id": "pWxsSyP1H3HW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-14 15:27:09.755772: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-14 15:27:11.685760: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747223832.299840    9923 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747223832.444498    9923 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1747223833.805279    9923 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1747223833.805309    9923 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1747223833.805310    9923 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1747223833.805311    9923 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-05-14 15:27:13.986226: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-14 15:27:48.838428: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m tv = TextVectorization(output_mode=\u001b[33m\"\u001b[39m\u001b[33mint\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# make a dictionary\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m tv.adapt(\u001b[43mdataset\u001b[49m)\n",
            "\u001b[31mNameError\u001b[39m: name 'dataset' is not defined"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# Create a text vectorizer based on keras layers\n",
        "tv = TextVectorization(output_mode=\"int\")\n",
        "\n",
        "# make a dictionary\n",
        "tv.adapt(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "988bd684",
      "metadata": {},
      "source": [
        "**Encoding/Decoding using `keras`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "AFAKQgQtPMKk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFAKQgQtPMKk",
        "outputId": "8f4bf45a-d08b-492e-e356-9e8eb3b2617e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded: [ 7  3  5  9  1  5 10]\n",
            "Decoded: i write rewrite and [UNK] rewrite again\n"
          ]
        }
      ],
      "source": [
        "voc = tv.get_vocabulary()\n",
        "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
        "encoded = tv(test_sentence)\n",
        "print(f'Encoded: {encoded}')\n",
        "\n",
        "inverse_voc = dict(enumerate(voc))\n",
        "\n",
        "decoded = \" \".join(inverse_voc[int(i)] for i in encoded)\n",
        "\n",
        "print(f'Decoded: {decoded}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cff9e87b",
      "metadata": {},
      "source": [
        "the vector generated by `keras`  : [ 7, 3, 5, 9, 1, 5, 10]\n",
        "\n",
        "the vector generated from scratch: [2, 3, 5, 7, 1, 5, 6]\n",
        "\n",
        "the results is deferent becuase indexing method is deferent."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
